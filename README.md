# README

![thumb-course-phthon-basic](README.assets/thumb-course-phthon-basic-1573569963444.jpg)

- Original Github link : [GitHub Storage](https://github.com/WegraLee/deep-learning-from-scratch)

- DL 기초부터 차근차근 배워가기 위해 만든 repository입니다.

#### Tip

- Anaconda를 설치한 후 Visual Studio Code에서 잡지 못하는 경우

  1. `source ~/Anaconda3/Scripts/activate` 명령어를 사용해 강제로 가상환경을 구축합니다.

  2. 주로 사용하는 python 라이브러리를 설치합니다.

  ```bash
  $ pip install numpy scipy matplotlib pandas ipython notebook scikit-learn
  ```

  > 이 외에도 추가로 필요한 라이브러리가 있다면 `pip install`로 설치하면 됩니다.

- backups에 대해

  - 해당 폴더는 다음 두 파일을 가지고 있습니다.

    1. `equations_and_figures.zip`: 각 장에 사용된 수식, 그림들을 압축한 파일입니다.

    2. `params.pkl`: chapter07. CNN에 사용된 파라미터의 정보가 담긴 `pickle` 파일입니다.

## 0. What I learned

- [chapter01. Hello, Python](https://github.com/Myeonghan-Jeong/deep-learning-from-scratch/tree/master/chapter01)

  - 1.1 What is python?

  - 1.2 Install python

  - 1.3 Python interpretor

  - 1.4 Python script file

  - 1.5 NumPy

  - 1.6 Matplotlib

  - 1.7 Summary

- [chapter02. Perceptron](https://github.com/Myeonghan-Jeong/deep-learning-from-scratch/tree/master/chapter02)

  - 2.1 What is perceptron?

  - 2.2 Simple logic cycle

  - 2.3 Make perceptron

  - 2.4 Limit of perceptron

  - 2.5 When multilayer perceptron moves

  - 2.6 from NAND to computer

  - 2.7 Summary

- [chapter03. Neural Network](https://github.com/Myeonghan-Jeong/deep-learning-from-scratch/tree/master/chapter03)

  - 3.1 from perceptron to neural network

  - 3.2 Activation function

  - 3.3 Calculation of multi-dimension matrixes

  - 3.4 Simulate multi layer neural network

  - 3.5 Design print layer

  - 3.6 Recognize handwriting

  - 3.7 Summary

- [chapter04. Learning Neural Network](https://github.com/Myeonghan-Jeong/deep-learning-from-scratch/tree/master/chapter04)

  - 4.1 Learn from data!

  - 4.2 Loss function

  - 4.3 Numerical differential

  - 4.4 Slope

  - 4.5 Simulate learning algorithm

  - 4.6 Summary

- [chapter05. Backpropagation](https://github.com/Myeonghan-Jeong/deep-learning-from-scratch/tree/master/chapter05)

  - 5.1 Calculation graph

  - 5.2 Chain rule

  - 5.3 Backpropagation

  - 5.4 Simulate simple layer

  - 5.5 Simulate activation function layer

  - 5.6 Simulate Affine/Softmax layer

  - 5.7 Simulate backpropagation

  - 5.8 Summary

- [chapter06. Technics about learning](https://github.com/Myeonghan-Jeong/deep-learning-from-scratch/tree/master/chapter06)

  - 6.1 Renewal parameters

  - 6.2 Initial value of wieght

  - 6.3 Bacth normalization

  - 6.4 for right learning

  - 6.5 Find suitable hyperparameters

  - 6.6 Summary

- [chapter07. CNN](https://github.com/Myeonghan-Jeong/deep-learning-from-scratch/tree/master/chapter07)

  - 7.1 Overall structure

  - 7.2 Convolutional layer

  - 7.3 Pooling layer

  - 7.4 Simulate convolutional / pooling layer

  - 7.5 Simulate CNN

  - 7.6 Visualize CNN

  - 7.7 Representative CNN

  - 7.8 Summary

- [chapter08. Deep Learning](https://github.com/Myeonghan-Jeong/deep-learning-from-scratch/tree/master/chapter08)

  - 8.1 More deeper

  - 8.2 The early history of deep learning

  - 8.3 More faster(speedy deep learning)
