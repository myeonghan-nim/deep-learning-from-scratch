# chapter08. Deep Learning

- 딥러닝은 층을 깊게 한 심층 신경망입니다.

- 이 싱층 신경망은 지금까지 배운 신경망을 바탕으로 뒷단에 층을 추가하디만 하면 만들 수 있습니다.

- 하지만 그렇게 만들기엔 여러 문제점이 많습니다.

- 이번 장에서는 딥러닝의 특징과 과제, 가능성을 살펴보고 오늘날 첨단 딥러닝도 배울 계획입니다.

## 8.1 더 깊게

- 신경망에 관해 그동안 많은 것을 배웠습니다.

  - 신경망을 구성하는 다양한 계층과 학습에 효과적인 기술

  - 영상 분야에 특히 유요한 CNN과 매개변수 최적화 기법 등 다양한 것을 배웠습니다.

- 이 모두는 딥러닝에서 매우 중요한 기술입니다.

- 이번 절은 배운 기술을 집약하고 심층 신경망을 만들어 MNIST 데이터셋 손글씨 숫자 인식에 도전합니다.

### 8.1.1 더 깊은 신경망으로

- 이번 절에서 만들 신경망은 다음 그림과 같습니다.

<img src="README.assets/fig 8-1-1579613756450.png" alt="fig 8-1" style="zoom:50%;" />

- 이전보다 더 깊은 신경망으로 특성은 다음과 같습니다.

  - 합성곱 계층은 모두 (3, 3) 크기의 작은 필터로 층이 깊어지면서 채널 수가 늘어납니다.

    - 앞에서부터 순서대로 16, 16, 32, 32, 64, 64로 증가합니다.

  - 풀링 계층을 중간중간 추가하여 중간 데이터의 공간 크기를 점차 줄여나갑니다.

  - 마지막 단의 완전연결 계층에서 드롭아웃 계층을 사용합니다.

  - 가중치 초깃값은 He 초깃값(활성화 함수는 ReLU)이며 가중치 매개변수 갱신은 Adam을 사용합니다.

> 이 신경망의 정확도는 약 99.38%입니다.

#### Note

- 이 신경망을 구현한 코드는 8.1.1_deep_convnet.py에 기록되어 있습니다.

- 반면 훈련용 코드는 8.1.1_train_deepnet.py에 기록되어 있습니다.

- 이 코드들을 직접 실행시키는 것도 좋지만 반나절 이상 걸릴 것이므로 deep_conv_net_params.pkl에 학습된 매개변수가 준비되어 있습니다.

> 다음 그림은 신경망이 인식하지 못한 이미지들 입니다.

<img src="README.assets/fig 8-2.png" alt="fig 8-2" style="zoom:50%;" />

- 이 사진들은 인간도 판단하기 어려운 이미지입니다.

- 이런 결과에 비추어 볼 때 심층 CNN은 인간과 비슷하게 인식할 정도로 잠재력이 크다는 점을 알 수 있습니다.

### 8.1.2 정확도를 높이려면?

- 다음 사진은 What is the class of this image? 라는 웹 사이트에서 다양한 데이터셋을 대상으로 그동안 발표된 기법들의 정확도 순위입니다.

<img src="README.assets/fig 8-3.png" alt="fig 8-3" style="zoom:50%;" />

- 순위를 보면 Neural Networks나 Deep, Convolutional이라는 키워드가 자주 등장함을 알 수 있습니다.

  - 상위권의 기법들은 대부분 CNN을 기초로 한 것이지만 깊이가 그다지 깊지 않습니다.

#### Note

- MNIST 데이터셋은 층이 매우 깊지 않아도 최고 수준의 결과가 나옵니다.

- 반면에 나중에 소개할 대규모 일반 사물 인식은 문제가 훨씬 복잡해지므로 층을 깊게해 정확도를 올릴 필요가 있습니다.

> 위 그림의 상위 기법들을 참고하면 정확도를 더 높일 수 있는 기술이나 힌트를 발견할 수 있습니다.
>
> 예를 들어 앙상블 학습, 학습률 감소, 데이터 확장 등이 여기서 나왔습니다.

- 여기서 **데이터 확장**이란 입력 이미지를 알고리즘을 동원해 인위적으로 확장하는 것을 말합니다.

<img src="README.assets/fig 8-4.png" alt="fig 8-4" style="zoom:50%;" />

- 데이터 확장은 다양한 방법으로 이루어집니다.

  - 예를 들어 이미지 일부를 자르는 crop, 좌우를 뒤집는 flip 등이 있습니다.

  - 그 외에도 밝기 변화, 확대 및 축소 등 스케일 변화 등 다양한 방법이 있습니다.

### 8.1.3 깊게 하는 이유

- 층을 깊게 하는 것이 왜 중요한지는 다음과 같이 설명할 수 있습니다.

  0. ILSVRC와 같은 대규모 이미지 인식 대회의 결과를 볼 때 층이 깊어질수록 더 좋은 결과를 가져옵니다.

  1. 신경망의 매개변수 수가 줄어듭니다. 층이 깊어질수록 더 적은 매개변수로 더 나은 결과를 얻을 수 있습니다.

     > 다음 그림은 (5, 5) 필터로 구성된 합성곱 계층의 예시입니다.

     <img src="README.assets/fig 8-5.png" alt="fig 8-5" style="zoom:50%;" />

     > 다음 그림은 (3, 3) 필터를 두 번 거친 합성곱 계층의 예시입니다.

     <img src="README.assets/fig 8-6.png" alt="fig 8-6" style="zoom:50%;" />

     - 여기서 (3, 3) 필터의 계산 결과는 (5, 5) 필터가 계산한 영역에서 계산한 결과와 비슷합니다.

     - 즉, (5, 5) 연산 1회는 (3, 3) 연산 2회로 대체할 수 있으면 매개변수도 25개에서 18개로 줄어듭니다.

     - 이 차이는 층이 깊어질수록 커지게 됩니다.

#### Note

- 작은 필터를 겹쳐 신경망을 깊게 할 때 장점은 매개변수 수를 줄여 넓은 **수용 영역**을 소화할 수 있는 점입니다.

  > 수용 영역이란 뉴런에 변화를 일으키는 국소적인 공간 영역을 의미합니다.

- 또한 층을 거듭하면 활성화 함수를 합성곱 계층 사이에 끼움으로써 신경망의 표현력이 개선됩니다.

  - 이는 활성화 함수가 신경망에 비선형 힘을 가하고 비선형 함수가 겹치면서 복잡한 것도 표현 가능하기 때문입니다.

  2. 학습의 효율성이 좋아집니다. 층을 깊게 하여 학습 데이터 양을 줄여 고속으로 수행할 수 있습니다.

     > 이해가 잘 가지 않는다면 7.6 CNN 시각화하기를 다시 확인하세요.

     - 예를 들어 개를 인식하는 문제를 예시로 들겠습니다.

     - 얕은 신경망은 개의 특징 대부분을 한 번에 이해해야 합니다.

       - 따라서 다양한 견종과 각도 등에 맞추어 변화가 풍부하고 많은 학습 데이터가 필요하며 시간이 오래 걸립니다.

     - 반면에 깊은 신경망은 이 문제를 계층적으로 분해할 수 있습니다.

       - 예를 들어 처음 층은 에지 학습에 전념해 적은 데이터로 효율적으로 학습할 수 있습니다.

  3. 정보를 계층 적으로 전달할 수 있습니다.

     - 예를 들어 에지를 추출한 층의 다음 층은 에지 정보를 사용할 수 있고 더 고도의 패턴을 효과적으로 학습하리라 기대할 수 있습니다.

     - 즉, 층을 깊게 함으로써 각 층이 학습해야 할 문제를 풀기 쉬운 단순한 문제로 분해할 수 있습니다.

- 다만 최근 일어나는 층의 심화는 층이 깊어도 제대로 학습할 수 있는 새로운 기술과 환경(빅데이터와 컴퓨터 연산 능력 등)이 뒷받침되어야 합니다.
