# chapter08. Deep Learning

- 딥러닝은 층을 깊게 한 심층 신경망입니다.

- 이 싱층 신경망은 지금까지 배운 신경망을 바탕으로 뒷단에 층을 추가하디만 하면 만들 수 있습니다.

- 하지만 그렇게 만들기엔 여러 문제점이 많습니다.

- 이번 장에서는 딥러닝의 특징과 과제, 가능성을 살펴보고 오늘날 첨단 딥러닝도 배울 계획입니다.

## 8.1 더 깊게

- 신경망에 관해 그동안 많은 것을 배웠습니다.

  - 신경망을 구성하는 다양한 계층과 학습에 효과적인 기술

  - 영상 분야에 특히 유요한 CNN과 매개변수 최적화 기법 등 다양한 것을 배웠습니다.

- 이 모두는 딥러닝에서 매우 중요한 기술입니다.

- 이번 절은 배운 기술을 집약하고 심층 신경망을 만들어 MNIST 데이터셋 손글씨 숫자 인식에 도전합니다.

### 8.1.1 더 깊은 신경망으로

- 이번 절에서 만들 신경망은 다음 그림과 같습니다.

<img src="README.assets/fig 8-1-1579613756450.png" alt="fig 8-1" style="zoom:50%;" />

- 이전보다 더 깊은 신경망으로 특성은 다음과 같습니다.

  - 합성곱 계층은 모두 (3, 3) 크기의 작은 필터로 층이 깊어지면서 채널 수가 늘어납니다.

    - 앞에서부터 순서대로 16, 16, 32, 32, 64, 64로 증가합니다.

  - 풀링 계층을 중간중간 추가하여 중간 데이터의 공간 크기를 점차 줄여나갑니다.

  - 마지막 단의 완전연결 계층에서 드롭아웃 계층을 사용합니다.

  - 가중치 초깃값은 He 초깃값(활성화 함수는 ReLU)이며 가중치 매개변수 갱신은 Adam을 사용합니다.

> 이 신경망의 정확도는 약 99.38%입니다.

#### Note

- 이 신경망을 구현한 코드는 8.1.1_deep_convnet.py에 기록되어 있습니다.

- 반면 훈련용 코드는 8.1.1_train_deepnet.py에 기록되어 있습니다.

- 이 코드들을 직접 실행시키는 것도 좋지만 반나절 이상 걸릴 것이므로 deep_conv_net_params.pkl에 학습된 매개변수가 준비되어 있습니다.

> 다음 그림은 신경망이 인식하지 못한 이미지들 입니다.

<img src="README.assets/fig 8-2.png" alt="fig 8-2" style="zoom:50%;" />

- 이 사진들은 인간도 판단하기 어려운 이미지입니다.

- 이런 결과에 비추어 볼 때 심층 CNN은 인간과 비슷하게 인식할 정도로 잠재력이 크다는 점을 알 수 있습니다.

### 8.1.2 정확도를 높이려면?

- 다음 사진은 What is the class of this image? 라는 웹 사이트에서 다양한 데이터셋을 대상으로 그동안 발표된 기법들의 정확도 순위입니다.

<img src="README.assets/fig 8-3.png" alt="fig 8-3" style="zoom:50%;" />

- 순위를 보면 Neural Networks나 Deep, Convolutional이라는 키워드가 자주 등장함을 알 수 있습니다.

  - 상위권의 기법들은 대부분 CNN을 기초로 한 것이지만 깊이가 그다지 깊지 않습니다.

#### Note

- MNIST 데이터셋은 층이 매우 깊지 않아도 최고 수준의 결과가 나옵니다.

- 반면에 나중에 소개할 대규모 일반 사물 인식은 문제가 훨씬 복잡해지므로 층을 깊게해 정확도를 올릴 필요가 있습니다.

> 위 그림의 상위 기법들을 참고하면 정확도를 더 높일 수 있는 기술이나 힌트를 발견할 수 있습니다.
>
> 예를 들어 앙상블 학습, 학습률 감소, 데이터 확장 등이 여기서 나왔습니다.

- 여기서 **데이터 확장**이란 입력 이미지를 알고리즘을 동원해 인위적으로 확장하는 것을 말합니다.

<img src="README.assets/fig 8-4.png" alt="fig 8-4" style="zoom:50%;" />

- 데이터 확장은 다양한 방법으로 이루어집니다.

  - 예를 들어 이미지 일부를 자르는 crop, 좌우를 뒤집는 flip 등이 있습니다.

  - 그 외에도 밝기 변화, 확대 및 축소 등 스케일 변화 등 다양한 방법이 있습니다.

### 8.1.3 깊게 하는 이유

- 층을 깊게 하는 것이 왜 중요한지는 다음과 같이 설명할 수 있습니다.

  0. ILSVRC와 같은 대규모 이미지 인식 대회의 결과를 볼 때 층이 깊어질수록 더 좋은 결과를 가져옵니다.

  1. 신경망의 매개변수 수가 줄어듭니다. 층이 깊어질수록 더 적은 매개변수로 더 나은 결과를 얻을 수 있습니다.

     > 다음 그림은 (5, 5) 필터로 구성된 합성곱 계층의 예시입니다.

     <img src="README.assets/fig 8-5.png" alt="fig 8-5" style="zoom:50%;" />

     > 다음 그림은 (3, 3) 필터를 두 번 거친 합성곱 계층의 예시입니다.

     <img src="README.assets/fig 8-6.png" alt="fig 8-6" style="zoom:50%;" />

     - 여기서 (3, 3) 필터의 계산 결과는 (5, 5) 필터가 계산한 영역에서 계산한 결과와 비슷합니다.

     - 즉, (5, 5) 연산 1회는 (3, 3) 연산 2회로 대체할 수 있으면 매개변수도 25개에서 18개로 줄어듭니다.

     - 이 차이는 층이 깊어질수록 커지게 됩니다.

#### Note

- 작은 필터를 겹쳐 신경망을 깊게 할 때 장점은 매개변수 수를 줄여 넓은 **수용 영역**을 소화할 수 있는 점입니다.

  > 수용 영역이란 뉴런에 변화를 일으키는 국소적인 공간 영역을 의미합니다.

- 또한 층을 거듭하면 활성화 함수를 합성곱 계층 사이에 끼움으로써 신경망의 표현력이 개선됩니다.

  - 이는 활성화 함수가 신경망에 비선형 힘을 가하고 비선형 함수가 겹치면서 복잡한 것도 표현 가능하기 때문입니다.

  2. 학습의 효율성이 좋아집니다. 층을 깊게 하여 학습 데이터 양을 줄여 고속으로 수행할 수 있습니다.

     > 이해가 잘 가지 않는다면 7.6 CNN 시각화하기를 다시 확인하세요.

     - 예를 들어 개를 인식하는 문제를 예시로 들겠습니다.

     - 얕은 신경망은 개의 특징 대부분을 한 번에 이해해야 합니다.

       - 따라서 다양한 견종과 각도 등에 맞추어 변화가 풍부하고 많은 학습 데이터가 필요하며 시간이 오래 걸립니다.

     - 반면에 깊은 신경망은 이 문제를 계층적으로 분해할 수 있습니다.

       - 예를 들어 처음 층은 에지 학습에 전념해 적은 데이터로 효율적으로 학습할 수 있습니다.

  3. 정보를 계층 적으로 전달할 수 있습니다.

     - 예를 들어 에지를 추출한 층의 다음 층은 에지 정보를 사용할 수 있고 더 고도의 패턴을 효과적으로 학습하리라 기대할 수 있습니다.

     - 즉, 층을 깊게 함으로써 각 층이 학습해야 할 문제를 풀기 쉬운 단순한 문제로 분해할 수 있습니다.

- 다만 최근 일어나는 층의 심화는 층이 깊어도 제대로 학습할 수 있는 새로운 기술과 환경(빅데이터와 컴퓨터 연산 능력 등)이 뒷받침되어야 합니다.

## 8.2 딥러닝의 초기 역사

- 딥러닝이 지금처럼 큰 주목을 받게 된 계기는 이미지 인식 기술을 겨루는 장인 ILSVRC 2012 대회이었습니다.

  - 해당 대회에서 딥러닝에 기초한 AlexNet이 압도적인 성적으로 우승하며 이미지 인식에 대한 접근법을 뿌리채 흔들었습니다.

- 이번 장에서는 최근 딥러닝 트렌드를 살펴보겠습니다.

### 8.2.1 이미지넷

- **이미지넷**은 100만 장이 넘는 이미지를 담고 있는 데이터셋입니다.

- 이들은 다음 그림과 같이 다양한 종류의 이미지와 각 이미지이 레이블이 붙어있습니다.

<img src="README.assets/fig 8-7.png" alt="fig 8-7" style="zoom:50%;" />

> 이 이미지 데이터셋을 활용해 자웅을 겨루는 대회가 ILSVRC입니다.

- ILSVRC에는 몇 가지 시험 항목이 있는데 그 중 하나가 **분류**입니다.

  - 분류 부문은 1000개의 클래스를 제대로 분류하는지 겨룹니다.

  - 다음 그래프는 최근까지 ILSVRC 분류 부분 우승팀의 성적으로 **Top-5 오류**를 막대 그래프로 나타내었습니다.

  - 여기서 Top-5 오류란 확률이 가장 높다고 생각하는 후보 클래스 5개 안에 정답이 포함되지 않은, 즉 5개 모두가 틀린 비율입니다.

  <img src="README.assets/fig 8-8.png" alt="fig 8-8" style="zoom:50%;" />

- 여기서 주목할 점은 2012년 이후 선두는 항상 딥러닝을 사용했다는 점입니다.

  - 실제로 2012년 AlexNet이 오류율을 크게 낮췄고 그 후 딥러닝을 활용한 기법이 꾸준히 정확도를 개선했습니다.

  - 특히 2015년 150층이 넘는 심층 신경망인 ResNet이 오류율을 3.5%까지 낮추며 인간의 인식 능력을 넘었다고 평가받고 있습니다.

- 이런 딥러닝 중 최근 몇 년 빼어난 성적을 거두고 있는 VGG, GoogLeNet, ResNet에 대해 간단히 알아보겠습니다.

### 8.2.2 VGG

- VGG는 합성곱 계층과 풀링 계층으로 구성되는 기본적인 CNN입니다.

- 다만, 다음 그림과 같이 비중 있는 층(합성곱 계층, 완전연결 계층)을 모두 16층 혹은 19층으로 심화한게 특징입니다.

<img src="README.assets/fig 8-9.png" alt="fig 8-9" style="zoom:50%;" />

> 층의 깊이에 따라 VGG16 혹은 VGG19로 구분하기도 합니다.

- VGG에서 주목할 점은 (3, 3) 작은 필터를 사용한 합성곱 계층을 연속으로 거친다는 것입니다.

- 합성곱 계층을 2 ~ 4개 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복하고 마지막에는 완전연결 계층을 통해 결과를 출력합니다.

#### Note

- VGG는 2014년 대회에서 2위를 한 딥러닝입니다.

- 성능 면에서는 GoogLeNet에 뒤지지만 구성이 간단해 응용하기 쉽습니다.

### 8.2.3 GoogLeNet

- GoogLeNet은 다음 그림과 같으며 그림의 사각형이 합성곱 계층과 풀링 계층 등 각 계층을 의미합니다.

<img src="README.assets/fig 8-10.png" alt="fig 8-10" style="zoom:50%;" />

- 구성이 매우 복잡해 보이지만 기본적으로 지금껏 보아온 CNN과 다르지 않습니다.

  - 다만 GoogLeNet은 세로 방향 깊이 말고 가로 방향 깊이도 깊다는 점이 특징입니다.

- GoogLeNet은 가로 반향 폭이 존재하는데 이를 인셉션 구조라고 합니다. 이는 다음과 같습니다.

<img src="README.assets/fig 8-11.png" alt="fig 8-11" style="zoom:50%;" />

- 인셉션 구조는 크기가 다른 필터와 풀링을 여러 개 적용하여 그 결과를 결합합니다.

- 이 구조를 하나의 빌딩 블록, 즉 구성요소로 사용하는 것이 GoogLeNet의 특징입니다.

- 또한 GoogLeNet은 (1, 1) 필터를 사용한 합성곱 계층을 많은 곳에서 사용하여 채널 쪽으로 크기를 줄여 매개변수 제거와 고속 처리에 기여합니다.

### 8.2.4 ResNet

- **ResNet**은 마이크로소프트 팀이 개발한 네트워크로 지금까지보다 층을 더 깊게 할 수 있는 특별한 장치가 존재합니다.

  - 딥러닝의 층을 깊게 하는 건 중요하지만 층이 지나치게 깊으면 학습이 잘 되지 않고 오히려 성능이 떨어지는 경우가 있습니다.

  - 이를 방지하기 위해 ResNet은 **스킵 연결**을 사용합니다.

    - 스킵 연결은 다음 그림처럼 입력 데이터를 합성곱 계층을 건너뛰어 바로 출력에 더하는 구조를 의미합니다.

    <img src="README.assets/fig 8-12.png" alt="fig 8-12" style="zoom:50%;" />

- 이처럼 입력 x를 연속한 두 합성곱 계층을 건너뛰어 출력에 바로 연결하여 출력을 f(x) + x로 만들어줍니다.

- 이 과정을 통해 층이 깊어져도 효율적으로 학습할 수 있도록 해주는데 이는 역전파 때 스킵 연결이 신호 감쇠를 막아주기 때문입니다.

#### Note

- 스킵 연결은 딥력 데이터를 그대로 흘리는 것으로 역전파 때도 상류의 기울기를 그대로 하류로 보냅니다.

- 여기서 핵심은 상류의 기울기가 아무런 수정도 없이 그대로 흐른다는 점입니다.

- 이 덕분에 스킵 연결로 기울기가 작아지거나 지나치게 커질 걱정 없이 앞 층에 의미 있는 기울기가 전해지리라 기대할 수 있습니다.

- 즉, 층을 깊게 할수록 기울기가 작아지는 소실 문제를 스킵 연결이 해결해줍니다.

> 다음 ResNet은 앞서 설명한 VGG 기반에 스킵 연결을 도입한 것입니다.

<img src="README.assets/fig 8-13.png" alt="fig 8-13" style="zoom:50%;" />

- 이와 같이 ResNet은 합성곱 계층을 2개 층마다 건너뛰면서 층을 깊게 합니다.

  - 실험 상 150층 이상으로 해도 정확도가 오르는 모습을 확인할 수 있으며 Top-5 오류율이 3.5%일 정도로 성능이 우수합니다.

#### Note

- 이미지넷이 제공하는 거대한 데이터셋으로 학습한 가중치 값들은 실제 제품에 활용해도 효과적입니다.

- 이를 **전이 학습**이라고 하며 학습된 가중치를 다른 신경망에 복사하여 재학습을 수행합니다.

  - 예를 들어 VGG와 구성이 같은 신경망을 준비하고 미리 학습된 가중치를 초깃값으로 설정한 후 새로운 데이터셋으로 재학습을 수행합니다.

- 이런 전이 학습은 보유한 데이터셋이 적을 때 특히 유용합니다.

## 8.3 더 빠르게(딥러닝 고속화)

- 빅데이터와 네트워크의 발전으로 딥러닝에서 대량의 연산을 수행할 일이 증가했습니다.

- 과거에는 연산을 CPU가 담당했으나 CPU만으로 처리하기에 부족하므로 실제 딥러닝 프레임워크 대부분은 **GPU**를 활용해 고속으로 처리합니다.

  - 최근 프레임워크는 복수의 GPU를 여러 기기로 분산 수행하기 시작했습니다.

### 8.3.1 풀어야 할 숙제

- 딥러닝의 고속화 얘기를 하기 앞서 딥러닝에서 어떤 처리에 시간이 소요되는 지 다음 그래프를 보면 알 수 있습니다.

  - 다음 그래프는 AlexNet의 forward 처리에서 각 층이 소비하는 시간입니다.

  <img src="README.assets/fig 8-14.png" alt="fig 8-14" style="zoom:50%;" />

- 그림에서 보듯 합성곱 계층에서 상당한 시간을 소요합니다.

  - 실제 합성곱 계층의 처리 시간을 다 더하면 GPU는 전체의 95%를 CPU는 전체의 89%를 소모합니다.

- 따라서 합성곱 계층에서 이루어지는 연산을 효율적으로 줄이는 것이 딥러닝의 과제입니다.

#### Note

- 합성곱 계층의 연산은 7.2 합성곱 계층에서 보듯 단일 곱셈 누산입니다.

- 따라서 딥러닝은 대량의 단일 곱셈 누산을 어떻게 고속으로 효율적으로 하는 지가 관건입니다.

### 8.3.2 GPU를 활용한 고속화

- GPU는 원래 그래픽 전용 보드였으나 최근 범용 수치 계산에도 이용됩니다.

  - 이는 GPU가 병렬 수치 연산을 고속으로 처리할 수 있으니 그를 활용하는 것으로 이를 **GPU 컴퓨팅**이라고 합니다.

- 딥러닝에서 대량의 단일 곱셈 누산 혹은 큰 행렬의 곱을 수행해야 합니다. 바로 이 부분이 GPU의 특기입니다.

  - 반면 CPU는 연속적인 복잡한 계산을 잘 처리합니다

- 그래서 딥러닝 연산에는 GPU를 이용하면 CPU만 사용할 때보다 놀라울 정도로 빠른 결과를 얻을 수 있습니다.

- 그 비교는 다음과 같으며 AlexNet에 대한 시간을 나타냈습니다.

<img src="README.assets/fig 8-15.png" alt="fig 8-15" style="zoom:50%;" />

- 이처럼 CPU에서 40여 일이 걸릴 계산이 GPU로 6일로 단축되었으며 cuDNN을 사용해 추가적으로 시간을 줄일 수 있음을 알 수 있습니다.

- GPU는 엔비디아와 AMD 주로 두 회사가 제공하나 아직 딥러닝에 더 활용 가능한 쪽은 엔비디아입니다.

  - 이는 엔비디아가 GPU 컴퓨팅용 통합 개발 환경 **CUDA**를 사용하기 때문입니다.

  - 즉, **cuDNN**은 CUDA를 사용해 동작하는 라이브러리로 딥러닝에 최적화된 함수 등이 구현되어 있습니다.

#### Note

- 합성곱 계층에서 행하는 연산은 im2col을 이용해 큰 행렬의 곱으로 변환할 수 있었습니다.

- 바로 이 방식은 GPU로 구형하기 적합합니다. 즉, GPU는 작은 단위의 게산보다 큰 덩어리의 계산 한 번에 더 유리합니다.

### 8.3.3 분산 학습

- GPU로 딥러닝 연산을 꽤 가속할 수 있으나 심층 신경망 학습에는 한계가 있습니다.

  - 또한, 딥러닝은 많은 시행착오를 거치며 뛰어난 신경망을 만들기 위해 학습에 걸리는 시간이 많습니다.

  - 그래서 1회 학습에 걸리는 시간을 단축하고자 하는 욕구가 필연적이며 이를 해결하기 위해 딥러닝 학습을 수평 확장하자는 아이디어가 중요한 것입니다.

- 딥러닝 계산을 더욱 고속화 하고자 다수의 GPU와 기기로 게산을 분산하기도 합니다.

  - 최근에 다수의 GPU와 컴퓨터를 이용한 분산 학습을 지원한 딥러닝 프레임워크들이 나타나고 있습니다.

  - 그 중 대표적인 것이 구글의 텐서플로, 마이크로소프트의 CNTK입니다.

- 거대한 데이터센터의 저지연, 고처리량 네트워크 위에서 이 프레임워크들이 수행하는 분산 학습은 놀라운 결과를 보여줍니다.

<img src="README.assets/fig 8-16.png" alt="fig 8-16" style="zoom:50%;" />

- 이처럼 GPU 수가 늘어남에 따라 학습도 빨라집니다.

- 다만 분산 학습도 어떻게 계산을 분산시키느냐는 매우 어려운 문제입니다.

  - 컴퓨터 사이의 통신, 데이터 동기화 등 쉽게 해결할 수 없는 문제들이 많습니다.

  - 따라서 이런 문제는 텐서플로 같은 뛰어난 프레임워크에 맡기는 것이 좋습니다.

### 8.3.4 연산 정밀도와 비트 줄이기

- 계산 능력 외에도 메모리 용량과 버스 대역폭 등이 딥러닝 고속화의 병목 장애물이 될 수 있습니다.

  - 메모리 용량 면에서 대량의 가중치 매개변수와 중간 데이터를 메모리에 저장해야 한다는 것을 생각해야 합니다.

  - 반면 버스 대역폭 면에서는 GPU 혹은 CPU의 버스를 흐르는 데이터가 많아져 한계를 넘어서면 병목이 됩니다.

- 이를 고려하면 네트워크로 주고받는 데이터의 비트 수는 최소로 만드는 것이 바람직합니다.

- 컴퓨터는 주로 32비트나 64비트 부동소수점 수를 사용해 실수를 표현합니다.

  - 많은 비트를 사용할수록 계산 오차는 줄어드나 그만큼 계산 비용과 메모리 사용량이 늘어 버스 대역폭에 부담을 줍니다/

- 다행히 딥러닝은 높은 수치 정밀도를 요구하지 않습니다.

  - 이는 신경망의 중요한 성질 중 하나로 신경망의 견고성에 따른 특성입니다.

    - 예를 들어, 신경망은 이미지에 노이즈가 조금 섞여 있어도 출력 결과가 잘 달라지지 않습니다.

  - 이 특성 덕분에 신경망을 흐르는 데이터를 퇴화시켜도 출력에 주는 영향은 적습니다.

- 컴퓨터에서 실수를 표현하는 방식으로 **32비트 단정밀도**와 **64비트 배정밀도** 부동소수점 등의 포맷이 있으나 일반적으로 딥러닝은 **16비트 반정밀도**로도 문제가 없습니다.

  - 실제로 엔비디아의 파스칼 아키텍처 GPU는 이 포맷을 지원하며 표준적으로 16비트가 사용됩니다.

#### Note

- 엔비디아의 파스칼 이전 GPU는 반정밀도 부동소수점 수를 데이터를 저장하는 기억으로 지원하고 있었으나 연산 자체는 16비트로 수행하지 않았습니다.

- 이 방식이 파스칼로 넘어오면 바뀌었고 연산도 2배 정도 빨라졌습니다.

> 지금까지 구현한 딥러닝은 수치 정밀도에 특별히 주의하지 않핬습니다.
>
> python은 일반적으로 64비트를 사용하나 numpy는 16비트도 지원하며 이를 사용해도 정확도가 떨어지지 않습니다.
>
> 자세한 비교는 chapter08/8.3.4_half_float_network.py를 확인하세요.

- 딥러닝의 비트 수를 줄이는 연구는 현재도 진행 중이며 최근에는 가중티와 중간 데이터는 1비트로 표현하는 방법도 등장했습니다.

  - 딥러닝을 고속화하기 위해 비트를 줄이는 기술은 앞으로도 주시할 부분이며 특히 딥러닝을 임베디드에 사용할 때 특히 중요한 주제입니다.

## 8.4 딥러닝의 활용

- 지금까지 배워온 딥러닝은 손글씨 숫자 인식 이미지 분류에 사용했습니다. 이는 사물 인식의 한 분야일 뿐입니다.

- 딥러닝은 사물 인식뿐만 아니라 온갖 문제를 해결할 수 있습니다. 이번 장에는 딥러닝의 활용 분야에 대해 알아볼 것입니다.

### 8.4.1 사물 검출

- 이미지 속에서 사물의 위치와 종류를 알아내는 사물 검출은 다음과 같이 진행됩니다.

<img src="README.assets/fig 8-17.png" alt="fig 8-17" style="zoom:50%;" />

- 이처럼 사물 검출은 사물 인식보다 어려운 문제입니다.

  - 사물 인식은 이미지 전체를 대상으로 했지만 사물 검출은 이미지 어딘가에 있을 사물의 위치까지 알아내야 하며 사물이 여러 개일 수 있습니다.

- 이를 CNN 기반으로 한 기번이 몇 가지 제안되었는데 그 중 가장 유명한 것은 **R-CNN**입니다.

<img src="README.assets/fig 8-18.png" alt="fig 8-18" style="zoom:50%;" />

- R-CNN의 처리 과정 중 후보 영역 추출과 CNN 특징 계산이 주목할 부분입니다.

  - 먼저 사물이 위치한 영역을 찾아내고 추출한 각 영역에 CNN을 적용해 클래스를 분류합니다.

  - 이미지를 사격형으로 변형하거나 분류할 때 서포트 벡터 머신을 사용하는 등 실제 처리 흐름은 다소 복잡하나 큰 틀은 위의 두 처리를 진행합니다.

- 후보 영역 추출에는 컴퓨터 비전 분야에서 발전해온 다양한 기법을 사용할 수 있으며 R-CNN 논문의 경우 selective search를 사용했습니다.

  - 최근에는 이 후보 영역 추출까지 CNN으로 처리하는 **faster R-CNN**까지 등장했으며 이 방식은 모든 일을 하나의 CNN으로 처리해 매우 빠릅니다.

### 8.4.2 분할

- **분할**이란 이미지를 픽셀 수준에서 분류하는 문제입니다. 이 방식은 다음과 같습니다.

<img src="README.assets/fig 8-19.png" alt="fig 8-19" style="zoom:50%;" />

- 이렇게 픽셀 단위로 채색된 지도 데이터를 추론할 때 모든 픽셀을 분류합니다.

- 이를 신경망을 이용해 분할하는 가장 단순한 방법은 모든 픽셀 각각을 추론하는 것입니다.

  - 예를 들어 어느 직사각형 영역의 중심 픽셀 클래스를 분류하는 신경망을 만들어 모든 픽셀을 대상으로 추론하는 작업을 거칩니다.

  - 이 방식대로 forward 처리를 모든 픽셀에 대해 하면 긴 시간이 걸리는데 이를 해결하는 방법이 **FCN**입니다.

    - 이 방식은 단 한 번의 forward로 모든 픽셀의 클래스를 분류하는 방법입니다.

    <img src="README.assets/fig 8-20.png" alt="fig 8-20" style="zoom:50%;" />

- FCN은 합성곱 계층만으로 구성된 네트워크로 CNN의 완전연결 계층을 그와 같은 기능을 하는 합성곱 계층으로 대체합니다.

  - 그래서 CNN이 중간 데이터의 공간 볼륨을 1차원으로 변환해 완전연결 계층에서 처리한 것과 갈리 FCN은 공간 볼륨을 유지할 채 마지막 출력까지 처리할 수 있습니다.

- FCN은 마지막에 공간 크기를 확대하는 처리를 도입하여 줄어든 중간 데이터를 입력 이미지와 같은 크기까지 단번에 확대할 수 있습니다.

  - FCN의 마지막에서 수행하는 확대는 이중 선형 보간으로 역합성곱 연산을 통해 이를 구현합니다.

#### Note

- 완전연결 게층에서는 출력이 모든 입력과 연결됩니다. 이를 합성곱 계층으로 구현할 수 있습니다.

  - 예를 들어 (32, 10, 10)인 데이터의 완전연결 계층의 출력 노드가 100개라면 합성곱 계층은 필터를 100개 준비해 완전히 같은 처리를 할 수 있습니다.

### 8.4.3 사진 캡션 생성

- 사진 캡션 생성은 컴퓨터 비전과 자연어를 융합한 연구로 다음과 같습니다.

<img src="README.assets/fig 8-21.png" alt="fig 8-21" style="zoom:50%;" />

- 이 방식을 처리하는 대표적인 모델이 **NIC**입니다.

  - NIC는 다음과 같이 심층 CNN과 자연어를 다루는 **순환 신경망**, 즉 RNN으로 구성됩니다.

  > RNN은 순환적 관계를 가지는 신경망으로 자연어나 시계열 데이터 등 연속된 데이터를 다룰 때 많이 활용합니다.

  <img src="README.assets/fig 8-22.png" alt="fig 8-22" style="zoom:50%;" />

- NIC는 CNN으로 사진에서 특징을 추출하고 그 특징을 RNN에 넘기고 RNN이 그 특징을 초깃값으로 텍스트를 순환적으로 생성합니다.

  - NIC는 CNN과 RNN을 조합한 간단한 구성으로 정확한 사진 캡션을 만들어냅니다. 이런 처리 방식을 **멀티모달 처리**라고 합니다.

#### Note

- RNN에서 R은 순환적을 의미하며 순환적이란 신경망의 순환적 네트워크 구조를 의미합니다.

- 이 구조로 인해 이전에 생성한 정보에 영향을 받는 것이 RNN의 특징입니다.

  - 예를 들어 나라는 단어 뒤에 잤다라는 단어를 붙이면 앞의 나에 영향을 받아 는이라는 조사가 붙고 최종적으로 나는 잤다라는 문장이 되는 것입니다.

- 이처럼 자연어와 시계열 데이터 등 연속성 있는 데이터는 RNN에서 과거의 정보를 기억하며 동작합니다.
